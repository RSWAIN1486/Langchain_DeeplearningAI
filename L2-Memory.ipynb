{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1rkNvis0WZFFxN2NGJIRWzQ9KswNlUjNU","authorship_tag":"ABX9TyO07QDeneF66UHS/sQiIHZM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"euJk9oq1b3ak"},"outputs":[],"source":["!pip install langchain\n","!pip install openai\n","!pip install tiktoken"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Rakesh/DairyGPT/Langchain"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ongKU0CWbktL","executionInfo":{"status":"ok","timestamp":1685983848428,"user_tz":-330,"elapsed":5,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"81e070fb-46ee-4af6-c883-5613181e4c9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Rakesh/DairyGPT/Langchain\n"]}]},{"cell_type":"code","source":["import os\n","import openai\n","\n","from dotenv import load_dotenv, find_dotenv\n","# _ = load_dotenv(find_dotenv()) # read local .env file\n","os.environ['OPENAI_API_KEY'] = <your-open-api-key>\n","openai.api_key = <your-open-api-key>\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"dWOUXW9aVRjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferMemory\n"],"metadata":{"id":"ZluVLv_JVn9Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Conversation Buffer Memory"],"metadata":{"id":"RBBjTYVFa_DP"}},{"cell_type":"code","source":["llm = ChatOpenAI(temperature=0.0)\n","memory = ConversationBufferMemory()\n","conversation = ConversationChain(\n","    llm=llm, \n","    memory = memory,\n","    verbose=False\n",")"],"metadata":{"id":"z43vbcQpV6Vw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Hi, my name is Rakesh and I am a senior ML engineer at Dvara E-Dairy\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"vHxX0ByXV9Kk","executionInfo":{"status":"ok","timestamp":1685983030828,"user_tz":-330,"elapsed":2664,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"1c097710-4622-491f-b98e-a0f6622749f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Hello Rakesh, it's nice to meet you! I am an AI language model designed to have conversations with humans. How can I assist you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["conversation.predict(input=\"How do I implement LLMs\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"bdTYPIM9WKTH","executionInfo":{"status":"ok","timestamp":1685983038667,"user_tz":-330,"elapsed":7844,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"144027f0-0ae7-414c-ac96-3a4ca89e9e96"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'LLMs, or Language Model Libraries, can be implemented using various programming languages such as Python, Java, or C++. There are also pre-built libraries available such as TensorFlow, PyTorch, and Hugging Face. The implementation process typically involves selecting a suitable library, defining the model architecture, training the model on a large corpus of text data, and fine-tuning the model for specific tasks. Would you like more information on any of these steps?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["conversation.predict(input=\"Hey do you know where do I work?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"27ZZ5LvIWWua","executionInfo":{"status":"ok","timestamp":1685983041784,"user_tz":-330,"elapsed":3124,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"e68c5b6a-0389-4064-bcc8-a003bb548716"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Yes, you mentioned earlier that you are a senior ML engineer at Dvara E-Dairy. Is there anything else I can help you with?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["print(memory.buffer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xkgVIaYeWfJU","executionInfo":{"status":"ok","timestamp":1685983041786,"user_tz":-330,"elapsed":17,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"262504d1-de7c-4b29-c835-19edaac0cd3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: Hi, my name is Rakesh and I am a senior ML engineer at Dvara E-Dairy\n","AI: Hello Rakesh, it's nice to meet you! I am an AI language model designed to have conversations with humans. How can I assist you today?\n","Human: How do I implement LLMs\n","AI: LLMs, or Language Model Libraries, can be implemented using various programming languages such as Python, Java, or C++. There are also pre-built libraries available such as TensorFlow, PyTorch, and Hugging Face. The implementation process typically involves selecting a suitable library, defining the model architecture, training the model on a large corpus of text data, and fine-tuning the model for specific tasks. Would you like more information on any of these steps?\n","Human: Hey do you know where do I work?\n","AI: Yes, you mentioned earlier that you are a senior ML engineer at Dvara E-Dairy. Is there anything else I can help you with?\n"]}]},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wk_TdLvOWivJ","executionInfo":{"status":"ok","timestamp":1685983041787,"user_tz":-330,"elapsed":13,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"398cfd96-2355-4e33-9356-2bc495f0f935"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"Human: Hi, my name is Rakesh and I am a senior ML engineer at Dvara E-Dairy\\nAI: Hello Rakesh, it's nice to meet you! I am an AI language model designed to have conversations with humans. How can I assist you today?\\nHuman: How do I implement LLMs\\nAI: LLMs, or Language Model Libraries, can be implemented using various programming languages such as Python, Java, or C++. There are also pre-built libraries available such as TensorFlow, PyTorch, and Hugging Face. The implementation process typically involves selecting a suitable library, defining the model architecture, training the model on a large corpus of text data, and fine-tuning the model for specific tasks. Would you like more information on any of these steps?\\nHuman: Hey do you know where do I work?\\nAI: Yes, you mentioned earlier that you are a senior ML engineer at Dvara E-Dairy. Is there anything else I can help you with?\"}"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["### Save these memory to json"],"metadata":{"id":"a0TMvBeibKt0"}},{"cell_type":"code","source":["import json\n","\n","from langchain.memory import ChatMessageHistory\n","from langchain.schema import messages_from_dict, messages_to_dict"],"metadata":{"id":"vD1G3zq9bQ2J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["extracted_messages = conversation.memory.chat_memory.messages\n","print(extracted_messages)\n","print(extracted_messages[1].content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JGyUIuxXihe","executionInfo":{"status":"ok","timestamp":1685983185015,"user_tz":-330,"elapsed":6,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"41b1a0fb-47a2-4f2f-9285-731f56597fb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[HumanMessage(content='Hi, my name is Rakesh and I am a senior ML engineer at Dvara E-Dairy', additional_kwargs={}, example=False), AIMessage(content=\"Hello Rakesh, it's nice to meet you! I am an AI language model designed to have conversations with humans. How can I assist you today?\", additional_kwargs={}, example=False), HumanMessage(content='How do I implement LLMs', additional_kwargs={}, example=False), AIMessage(content='LLMs, or Language Model Libraries, can be implemented using various programming languages such as Python, Java, or C++. There are also pre-built libraries available such as TensorFlow, PyTorch, and Hugging Face. The implementation process typically involves selecting a suitable library, defining the model architecture, training the model on a large corpus of text data, and fine-tuning the model for specific tasks. Would you like more information on any of these steps?', additional_kwargs={}, example=False), HumanMessage(content='Hey do you know where do I work?', additional_kwargs={}, example=False), AIMessage(content='Yes, you mentioned earlier that you are a senior ML engineer at Dvara E-Dairy. Is there anything else I can help you with?', additional_kwargs={}, example=False)]\n","Hello Rakesh, it's nice to meet you! I am an AI language model designed to have conversations with humans. How can I assist you today?\n"]}]},{"cell_type":"code","source":["ingest_to_db = messages_to_dict(extracted_messages)"],"metadata":{"id":"s0VFxfzAbEbO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ingest_to_db"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aY116imAdogp","executionInfo":{"status":"ok","timestamp":1685983989912,"user_tz":-330,"elapsed":555,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"b3b5781a-43a5-4795-c679-f6f773bbbc3c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'type': 'human',\n","  'data': {'content': 'Hi, my name is Rakesh and I am a senior ML engineer at Dvara E-Dairy',\n","   'additional_kwargs': {},\n","   'example': False}},\n"," {'type': 'ai',\n","  'data': {'content': \"Hello Rakesh, it's nice to meet you! I am an AI language model designed to have conversations with humans. How can I assist you today?\",\n","   'additional_kwargs': {},\n","   'example': False}},\n"," {'type': 'human',\n","  'data': {'content': 'How do I implement LLMs',\n","   'additional_kwargs': {},\n","   'example': False}},\n"," {'type': 'ai',\n","  'data': {'content': 'LLMs, or Language Model Libraries, can be implemented using various programming languages such as Python, Java, or C++. There are also pre-built libraries available such as TensorFlow, PyTorch, and Hugging Face. The implementation process typically involves selecting a suitable library, defining the model architecture, training the model on a large corpus of text data, and fine-tuning the model for specific tasks. Would you like more information on any of these steps?',\n","   'additional_kwargs': {},\n","   'example': False}},\n"," {'type': 'human',\n","  'data': {'content': 'Hey do you know where do I work?',\n","   'additional_kwargs': {},\n","   'example': False}},\n"," {'type': 'ai',\n","  'data': {'content': 'Yes, you mentioned earlier that you are a senior ML engineer at Dvara E-Dairy. Is there anything else I can help you with?',\n","   'additional_kwargs': {},\n","   'example': False}}]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["with open('conversation_Rakesh.json', 'w', encoding='utf-8') as f:\n","  json.dump(ingest_to_db, f, ensure_ascii=False, indent=4)"],"metadata":{"id":"v4SGM_JbdpWF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load saved conversation and start new "],"metadata":{"id":"2HLXOWFkfFc2"}},{"cell_type":"code","source":["# Read JSON file\n","with open('conversation_Rakesh.json') as data_file:\n","    retrieved_conversation = json.load(data_file)\n","\n","retrieved_messages = messages_from_dict(retrieved_conversation)\n","retrieved_chat_history = ChatMessageHistory(messages=retrieved_messages)\n","retrieved_memory = ConversationBufferMemory(chat_memory=retrieved_chat_history)"],"metadata":{"id":"4JEjETorets3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation_new = ConversationChain(\n","    llm=llm, \n","    memory = retrieved_memory,\n","    verbose=False\n",")"],"metadata":{"id":"YkKTR6h_f4lv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation_new.predict(input=\"What is my name and what do i do?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"er8KyfyegAib","executionInfo":{"status":"ok","timestamp":1685991356773,"user_tz":-330,"elapsed":5018,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"13b7204a-8482-4c99-96c7-1257c8394636"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'As I mentioned earlier, your name is Rakesh and you are a senior ML engineer at Dvara E-Dairy. Is there anything else I can help you with?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["### ConversationBufferWindowMemory"],"metadata":{"id":"hUDsluVD6p6o"}},{"cell_type":"code","source":["from langchain.memory import ConversationBufferWindowMemory"],"metadata":{"id":"avMyxSNfgIIL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm = ChatOpenAI(temperature=0.0)\n","memory = ConversationBufferWindowMemory(k=1)\n","conversation = ConversationChain(\n","    llm=llm, \n","    memory = memory,\n","    verbose=False\n",")"],"metadata":{"id":"6tr4xH4K62jd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Hi, my name is Rakesh and I am a senior ML engineer at Dvara E-Dairy\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"pGoZ3-XO7Fp_","executionInfo":{"status":"ok","timestamp":1685991502695,"user_tz":-330,"elapsed":3672,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"0d08051c-2ff6-4bd5-8d3b-ba4059feac63"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Hello Rakesh, it's nice to meet you! I am an AI language model designed to have conversations with humans. How can I assist you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["conversation.predict(input=\"What does gradient descent work?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"id":"VI1VL9ND7KF8","executionInfo":{"status":"ok","timestamp":1685991604650,"user_tz":-330,"elapsed":8429,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"98793ed9-0b52-4042-eb3b-034c00ecc455"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Gradient descent is an optimization algorithm commonly used in machine learning to minimize the error or loss function of a model. It works by iteratively adjusting the parameters of the model in the direction of the steepest descent of the gradient of the loss function. This process continues until the algorithm reaches a minimum point where the gradient is zero or close to zero. The learning rate is an important hyperparameter that determines the step size of the algorithm at each iteration.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["conversation.predict(input=\"Who am I and what do i do?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"mnkptBUX7Rj9","executionInfo":{"status":"ok","timestamp":1685991618587,"user_tz":-330,"elapsed":3967,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"5c2908c9-e305-425c-877c-39a5ffd2b611"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"I'm sorry, but I don't have access to that information. Could you please tell me a bit more about yourself?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["### ConversationTokenBufferMemory"],"metadata":{"id":"SqCySfuH72CQ"}},{"cell_type":"code","source":[],"metadata":{"id":"EwyOF53J8K2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.memory import ConversationTokenBufferMemory\n","from langchain.llms import OpenAI\n","llm = ChatOpenAI(temperature=0.0)"],"metadata":{"id":"bePM8rqc7mVx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n","memory.save_context({\"input\": \"AI is what?!\"},\n","                    {\"output\": \"Amazing!\"})\n","memory.save_context({\"input\": \"Backpropagation is what?\"},\n","                    {\"output\": \"Beautiful!\"})\n","memory.save_context({\"input\": \"Chatbots are what?\"}, \n","                    {\"output\": \"Charming!\"})\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lshue8Zr8DQm","executionInfo":{"status":"ok","timestamp":1685991787118,"user_tz":-330,"elapsed":2520,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"329a0747-dc2e-42ed-feaa-6d77ac468b9a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=100)\n","memory.save_context({\"input\": \"AI is what?!\"},\n","                    {\"output\": \"Amazing!\"})\n","memory.save_context({\"input\": \"Backpropagation is what?\"},\n","                    {\"output\": \"Beautiful!\"})\n","memory.save_context({\"input\": \"Chatbots are what?\"}, \n","                    {\"output\": \"Charming!\"})\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sUznXHbG8I0E","executionInfo":{"status":"ok","timestamp":1685991849012,"user_tz":-330,"elapsed":6,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"e171f2a5-f947-4dff-9589-ca7d16b64459"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: AI is what?!\\nAI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["### ConversationSummaryMemory"],"metadata":{"id":"20jrl_ic8iL-"}},{"cell_type":"code","source":["from langchain.memory import ConversationSummaryBufferMemory"],"metadata":{"id":"5Xt0edE-8fYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a long string\n","schedule = \"There is a meeting at 8am with your product team. \\\n","You will need your powerpoint presentation prepared. \\\n","9am-12pm have time to work on your LangChain \\\n","project which will go quickly because Langchain is such a powerful tool. \\\n","At Noon, lunch at the italian resturant with a customer who is driving \\\n","from over an hour away to meet you to understand the latest in AI. \\\n","Be sure to bring your laptop to show the latest LLM demo.\"\n","\n","memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=400)\n","memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n","memory.save_context({\"input\": \"Not much, just hanging\"},\n","                    {\"output\": \"Cool\"})\n","memory.save_context({\"input\": \"What is on the schedule today?\"}, \n","                    {\"output\": f\"{schedule}\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_zTfYpe8lhN","executionInfo":{"status":"ok","timestamp":1685992168081,"user_tz":-330,"elapsed":585,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"2ed58ce3-6e53-4e56-c5db-f29a68e36f20"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"Human: Hello\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\\nHuman: What is on the schedule today?\\nAI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.\"}"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["# create a long string\n","schedule = \"There is a meeting at 8am with your product team. \\\n","You will need your powerpoint presentation prepared. \\\n","9am-12pm have time to work on your LangChain \\\n","project which will go quickly because Langchain is such a powerful tool. \\\n","At Noon, lunch at the italian resturant with a customer who is driving \\\n","from over an hour away to meet you to understand the latest in AI. \\\n","Be sure to bring your laptop to show the latest LLM demo.\"\n","\n","memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n","memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n","memory.save_context({\"input\": \"Not much, just hanging\"},\n","                    {\"output\": \"Cool\"})\n","memory.save_context({\"input\": \"What is on the schedule today?\"}, \n","                    {\"output\": f\"{schedule}\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rhU-dVUN9SUo","executionInfo":{"status":"ok","timestamp":1685992178034,"user_tz":-330,"elapsed":5085,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"077b6adf-346b-4c64-e8b1-ae7df54ed5f9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments.\"}"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["conversation = ConversationChain(\n","    llm=llm, \n","    memory = memory,\n","    verbose=False\n",")"],"metadata":{"id":"45vYm4h-9uez"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"What would be a good demo to show?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"LaRsQMI291Ke","executionInfo":{"status":"ok","timestamp":1685992276305,"user_tz":-330,"elapsed":13715,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"b6467f9d-ffce-47e2-c4f7-7227bede5b92"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Based on the customer's interests, I would recommend showcasing our natural language processing capabilities. We could demonstrate how our AI can understand and respond to complex language queries, and even provide personalized recommendations based on the customer's preferences. Additionally, we could showcase our machine learning algorithms and how they can improve accuracy and efficiency in various industries.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oHMbsK6R9768","executionInfo":{"status":"ok","timestamp":1685992288465,"user_tz":-330,"elapsed":5,"user":{"displayName":"Dvara Tech","userId":"11920201384607812533"}},"outputId":"8b39da66-fcc3-4c3f-a055-6ed8924b4ca8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments. The human asks about the lunch meeting and the AI explains that it's a great opportunity to showcase their latest advancements and discuss potential collaborations.\\nHuman: What would be a good demo to show?\\nAI: Based on the customer's interests, I would recommend showcasing our natural language processing capabilities. We could demonstrate how our AI can understand and respond to complex language queries, and even provide personalized recommendations based on the customer's preferences. Additionally, we could showcase our machine learning algorithms and how they can improve accuracy and efficiency in various industries.\"}"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":[],"metadata":{"id":"SLvjVy8S-Ksi"},"execution_count":null,"outputs":[]}]}